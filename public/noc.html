<!DOCTYPE html>
<html>
<head>
<style>
body {
  margin: 0;
  padding: 0;
  background-image: url('noc.jpg');
  background-size: cover;
  background-position: center;
  background-attachment: fixed;
  min-height: 100vh;
  font-family: 'Arial', sans-serif;
  position: relative;
}

/* Dark overlay for better text visibility */
body::before {
  content: '';
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0, 0, 0, 0.4);
  z-index: -1;
}

/* SkyElectric heading with sparkling effect */
.skyelectric-heading {
  position: absolute;
  top: 20px;
  left: 20px;
  font-size: 2.5em;
  font-weight: bold;
  color: #00d4ff;
  text-shadow: 0 0 10px #00d4ff, 0 0 20px #00d4ff, 0 0 30px #00d4ff;
  animation: sparkle 2s ease-in-out infinite alternate;
}

@keyframes sparkle {
  0% {
    text-shadow: 0 0 10px #00d4ff, 0 0 20px #00d4ff, 0 0 30px #00d4ff;
    filter: brightness(1);
  }
  100% {
    text-shadow: 0 0 20px #00d4ff, 0 0 30px #00d4ff, 0 0 40px #00d4ff, 0 0 50px #ffffff;
    filter: brightness(1.3);
  }
}

/* Add floating sparkles */
.sparkle {
  position: absolute;
  width: 4px;
  height: 4px;
  background: #ffffff;
  border-radius: 50%;
  animation: float 3s ease-in-out infinite;
}

.sparkle:nth-child(1) { top: 25px; left: 50px; animation-delay: 0s; }
.sparkle:nth-child(2) { top: 35px; left: 120px; animation-delay: 0.5s; }
.sparkle:nth-child(3) { top: 30px; left: 200px; animation-delay: 1s; }
.sparkle:nth-child(4) { top: 45px; left: 80px; animation-delay: 1.5s; }

@keyframes float {
  0%, 100% { transform: translateY(0px) scale(0.8); opacity: 0.7; }
  50% { transform: translateY(-10px) scale(1.2); opacity: 1; }
}

/* Main container for centering content */
.main-container {
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  min-height: 100vh;
  padding: 20px;
}

/* Big beautiful accept button */
#acceptBtn {
  background: linear-gradient(45deg, #28a745, #20c997);
  border: none;
  border-radius: 50px;
  padding: 25px 60px;
  font-size: 1.8em;
  font-weight: bold;
  color: white;
  cursor: pointer;
  box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
  transition: all 0.3s ease;
  text-transform: uppercase;
  letter-spacing: 2px;
  position: relative;
  overflow: hidden;
  display: none;
}

#acceptBtn:hover {
  transform: translateY(-5px);
  box-shadow: 0 12px 35px rgba(0, 0, 0, 0.4);
  background: linear-gradient(45deg, #218838, #17a2b8);
}

#acceptBtn:active {
  transform: translateY(-2px);
}

#acceptBtn:disabled {
  background: #666;
  cursor: not-allowed;
  transform: none;
  box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
}

/* Button shine effect */
#acceptBtn::before {
  content: '';
  position: absolute;
  top: 0;
  left: -100%;
  width: 100%;
  height: 100%;
  background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.3), transparent);
  transition: left 0.5s;
}

#acceptBtn:hover::before {
  left: 100%;
}

/* Status styling */
#status {
  color: white;
  font-size: 1.2em;
  margin: 20px 0;
  text-align: center;
  background: rgba(0, 0, 0, 0.5);
  padding: 10px 20px;
  border-radius: 25px;
  backdrop-filter: blur(10px);
}

/* Log styling */
#log {
  background: rgba(0, 0, 0, 0.7);
  color: #00ff00;
  padding: 20px;
  border-radius: 10px;
  max-height: 200px;
  overflow-y: auto;
  margin-top: 20px;
  font-family: 'Courier New', monospace;
  font-size: 0.9em;
  max-width: 80vw;
  backdrop-filter: blur(5px);
  border: 1px solid rgba(0, 255, 0, 0.3);
}
</style>
</head>
<body>
<div class="skyelectric-heading">
  SkyElectric
  <div class="sparkle"></div>
  <div class="sparkle"></div>
  <div class="sparkle"></div>
  <div class="sparkle"></div>
</div>

<div class="main-container">
  <button id="acceptBtn" style="display: none;">Accept Call</button>
  <p id="status">Waiting for calls...</p>
  <div id="log"></div>
</div>

<script src="/socket.io/socket.io.js"></script>
<script>
// Polyfill for older browsers
if (!navigator.mediaDevices) {
  navigator.mediaDevices = {};
}
if (!navigator.mediaDevices.getUserMedia) {
  navigator.mediaDevices.getUserMedia = function(constraints) {
    const getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
    if (!getUserMedia) {
      return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
    }
    return new Promise((resolve, reject) => {
      getUserMedia.call(navigator, constraints, resolve, reject);
    });
  };
}

const ws = io();
ws.emit("join", "noc");

const logDiv = document.getElementById("log");
const status = document.getElementById("status");

let pc, localStream;

function log(msg){ logDiv.innerHTML += msg + "<br>"; }

document.getElementById("acceptBtn").onclick = async () => {
  // Prevent multiple clicks
  const acceptBtn = document.getElementById("acceptBtn");
  acceptBtn.disabled = true;
  acceptBtn.style.display = "none";

  try {
    status.innerText = "Setting up connection...";
    // log("Checking media devices availability...");

    // Check if media devices are available
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      throw new Error("Media devices not available. Please use HTTPS or localhost");
    }

    // log("Requesting microphone access...");
    localStream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      } 
    });
    // log("Microphone access granted");

    pc = new RTCPeerConnection({
      iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
    });

    // Add connection state monitoring
    pc.onconnectionstatechange = () => {
      // log(`Connection state: ${pc.connectionState}`);
      if (pc.connectionState === 'connected') {
        status.innerText = "Voice call connected";
        // log("WebRTC connection established successfully!");
      }
    };

    pc.oniceconnectionstatechange = () => {
      // log(`ICE connection state: ${pc.iceConnectionState}`);
    };
    
    localStream.getTracks().forEach(track => {
      pc.addTrack(track, localStream);
      // log("Added local audio track");
    });

    const audio = document.createElement("audio");
    audio.autoplay = true;
    audio.controls = true; // Add controls for debugging
    pc.ontrack = e => {
      // log("Received remote audio stream");
      audio.srcObject = e.streams[0];
      status.innerText = "Connected to User";
      // log("Voice connection established - audio element created");
    };
    document.body.appendChild(audio);

    pc.onicecandidate = e => {
      if (e.candidate) {
        // Send the complete candidate object, not just the candidate string
        ws.emit("signal", { to: "user", data: {
          candidate: e.candidate.candidate,
          sdpMid: e.candidate.sdpMid,
          sdpMLineIndex: e.candidate.sdpMLineIndex
        }});
        // log("Sent ICE candidate to user");
      } else {
        // log("ICE gathering completed");
      }
    };

    startSTT("NOC said: ");
    ws.emit("accept_call");
    // log("Call accepted, waiting for offer...");
  } catch (error) {
    // log("Error setting up call: " + error.message);
    status.innerText = "Error setting up call";
    // Re-enable button on error
    acceptBtn.disabled = false;
    acceptBtn.style.display = "block";
  }
};

ws.on("incoming_call", () => {
  status.innerText = "Incoming call from User";
  document.getElementById("acceptBtn").style.display = "block";
  // log("Incoming call - click Accept to answer");
});

ws.on("signal", async data => {
  if (!pc) {
    // log("ERROR: Received signal but no peer connection exists");
    return;
  }

  try {
    if (data.type === "offer") {
      // log("Received offer from user");
      // log("Offer SDP: " + JSON.stringify(data).substring(0, 100) + "...");
      
      await pc.setRemoteDescription(new RTCSessionDescription(data));
      // log("Set remote description (offer)");
      
      const answer = await pc.createAnswer();
      // log("Created answer");
      
      await pc.setLocalDescription(answer);
      // log("Set local description (answer)");
      
      ws.emit("signal", { to: "user", data: answer });
      // log("Sent answer to user");
    }

    if (data.candidate) {
      // Validate that data.candidate is a proper ICE candidate object
      if (typeof data.candidate === 'string' && data.candidate.startsWith('candidate:')) {
        // Handle string candidates (legacy format)
        try {
          await pc.addIceCandidate(new RTCIceCandidate({
            candidate: data.candidate,
            sdpMid: data.sdpMid || null,
            sdpMLineIndex: data.sdpMLineIndex || 0
          }));
          // log("Added ICE candidate from user (string format)");
        } catch (candidateError) {
          // log("Error adding string ICE candidate: " + candidateError.message);
        }
      } else if (data.candidate && typeof data.candidate === 'object') {
        // Handle object candidates (proper format)
        try {
          await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
          // log("Added ICE candidate from user (object format)");
        } catch (candidateError) {
          // log("Error adding object ICE candidate: " + candidateError.message);
        }
      } else {
        // log("Received invalid ICE candidate data: " + JSON.stringify(data.candidate));
      }
    }
  } catch (error) {
    // log("Error handling signal: " + error.message);
    // log("Stack: " + error.stack);
  }
});

// Speech-to-text
function startSTT(prefix){
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) return;
  const r = new SR();
  r.continuous = true;
  r.interimResults = false;
  r.onresult = e => {}; // log(prefix + e.results[e.results.length-1][0].transcript);
  r.start();
}
</script>
</body>
</html>
